# üéôÔ∏è Whisper Speech-to-Text Platform

> **A self-hosted, full-stack audio transcription platform built with OpenAI Whisper, FastAPI, and React.**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Docker](https://img.shields.io/badge/Docker-Enabled-blue.svg)](https://hub.docker.com/r/riyazparasara/speech_to_text)
[![React](https://img.shields.io/badge/Frontend-React-61DAFB.svg)](https://reactjs.org/)
[![FastAPI](https://img.shields.io/badge/Backend-FastAPI-009688.svg)](https://fastapi.tiangolo.com/)

---

## üåü Features

- **High Accuracy Transcription**: Powered by OpenAI's **Whisper** models (`large-v3`, `turbo`, `medium`).
- **Multi-Language Support**: Automatically handles **Hindi**, **English**, and mixed-language (Hinglish) audio.
- **Rich File Support**: Upload `MP3`, `WAV`, `MP4`, `M4A`, `OGG`, `FLAC`, and `WEBM`.
- **Detailed Segments**: View precise start/end timestamps for every sentence.
- **Docker Ready**: One-command deployment.
- **Modern UI**: Clean, responsive interface for managing transcription jobs.

---

## üöÄ Quick Start (Docker)

The fastest way to run the application is using the pre-built images from Docker Hub.

### 1. Create a `docker-compose.yml`

Copy the content below into a file named `docker-compose.yml`:

```yaml
version: '3.8'

services:
  backend:
    image: riyazparasara/speech_to_text:backend
    ports:
      - "8000:8000"
    volumes:
      - ./uploads:/app/backend/uploads
      - ./transcripts:/app/backend/transcripts
    environment:
      # Options: tiny, base, small, medium, large-v3, turbo
      - WHISPER_MODEL=turbo
    restart: always

  frontend:
    image: riyazparasara/speech_to_text:frontend
    ports:
      - "3000:80"
    restart: always
```

### 2. Run the Application

```bash
docker-compose up -d
```

### 3. Access

- **Frontend**: [http://localhost:3000](http://localhost:3000)
- **API Docs**: [http://localhost:8000/docs](http://localhost:8000/docs)

*Note: The first run may take time to download the Whisper model file.*

---

## üõ†Ô∏è Development Setup

To build and run from source:

### Prerequisites
- Python 3.9+
- Node.js 18+
- FFmpeg

### 1. Clone & Setup Backend
```bash
git clone https://github.com/riyazparasara/speech_to_text.git
cd speech_to_text/backend

python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Run Server
uvicorn main:app --reload
```

### 2. Setup Frontend
```bash
cd ../frontend
npm install
npm run dev
```

---

## üîÆ Configuration

| Variable | Description | Default |
|----------|-------------|---------|
| `WHISPER_MODEL` | The Whisper model size to use. (`tiny`, `base`, `small`, `medium`, `large-v3`, `turbo`) | `large-v3` |

---

## üìú License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
